#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ìˆ˜ì •ëœ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_crawler():
    """ìˆ˜ì •ëœ í¬ë¡¤ëŸ¬ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("ğŸš€ ìˆ˜ì •ëœ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        from news_crawler import NateNewsCrawler
        
        crawler = NateNewsCrawler()
        
        # ê²½ì œ ë‰´ìŠ¤ë§Œ í…ŒìŠ¤íŠ¸ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´)
        print("ğŸ“° ê²½ì œ ë‰´ìŠ¤ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸...")
        economy_news = crawler.get_news_list('economy')
        
        print(f"âœ… ê²½ì œ ë‰´ìŠ¤ {len(economy_news)}ê°œ ìˆ˜ì§‘")
        
        if economy_news:
            print("\nğŸ“‹ ìˆ˜ì§‘ëœ ë‰´ìŠ¤:")
            for i, news in enumerate(economy_news[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                print(f"\n{i}. {news['title']}")
                print(f"   ì–¸ë¡ ì‚¬: {news['press']}")
                print(f"   ë§í¬: {news['link']}")
                print(f"   ìˆœìœ„: {news['rank']}")
            
            # ì²« ë²ˆì§¸ ë‰´ìŠ¤ì˜ ìƒì„¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            if economy_news:
                print(f"\nğŸ” ì²« ë²ˆì§¸ ë‰´ìŠ¤ ìƒì„¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°...")
                detailed_news = crawler.get_news_content(economy_news[0])
                
                if detailed_news:
                    print(f"âœ… ìƒì„¸ ë‚´ìš© ìˆ˜ì§‘ ì„±ê³µ")
                    print(f"   ì œëª©: {detailed_news['title']}")
                    print(f"   ë‚´ìš© ê¸¸ì´: {len(detailed_news.get('content', ''))}ì")
                    print(f"   ìš”ì•½: {detailed_news.get('summary', 'N/A')}")
                    print(f"   ì´ë¯¸ì§€: {detailed_news.get('image_url', 'N/A')}")
                else:
                    print("âŒ ìƒì„¸ ë‚´ìš© ìˆ˜ì§‘ ì‹¤íŒ¨")
        
        print("\nâœ… í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_crawler()
